{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-T5/T5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"project_root/Sentence pairs in English-Hindi - 2025-02-11.tsv\",sep=\"\\t\",header=None,\n",
    "                   names=[\"SrcSentenceID\",\"SrcSentence\",\"DstSentenceID\",\"DstSentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>485968</td>\n",
       "      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>2060319</td>\n",
       "      <td>म्यूरियल अब बीस साल की है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>Education in this world disappoints me.</td>\n",
       "      <td>485564</td>\n",
       "      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>That won't happen.</td>\n",
       "      <td>2060320</td>\n",
       "      <td>वैसा नहीं होगा।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>I miss you.</td>\n",
       "      <td>2060321</td>\n",
       "      <td>मुझें तुम्हारी याद आ रही है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                              SrcSentence  DstSentenceID  \\\n",
       "0           1282                       Muiriel is 20 now.         485968   \n",
       "1           1282                       Muiriel is 20 now.        2060319   \n",
       "2           1294  Education in this world disappoints me.         485564   \n",
       "3           1302                       That won't happen.        2060320   \n",
       "4           1308                              I miss you.        2060321   \n",
       "\n",
       "                                   DstSentence  \n",
       "0             म्यूरियल अब बीस साल की हो गई है।  \n",
       "1                   म्यूरियल अब बीस साल की है।  \n",
       "2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n",
       "3                              वैसा नहीं होगा।  \n",
       "4                 मुझें तुम्हारी याद आ रही है।  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13182, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[▁I, ▁miss, ▁you, .]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                                        SrcSentence  \\\n",
       "0           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "1           1282                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n",
       "2           1294  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n",
       "3           1302                    [▁That, ▁won, ', t, ▁happen, .]   \n",
       "4           1308                               [▁I, ▁miss, ▁you, .]   \n",
       "\n",
       "   DstSentenceID                                        DstSentence  \n",
       "0         485968        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1        2060319                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2         485564  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3        2060320                              [वैसा, नहीं, होगा, ।]  \n",
       "4        2060321              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SrcSentence\"] = data[\"SrcSentence\"].apply(tokenizer.convert_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd = set()\n",
    "for tokenized_hindi_sentence in data[\"DstSentence\"]:\n",
    "    Vd.update(tokenized_hindi_sentence)\n",
    "\n",
    "hindi_vocab = dict()\n",
    "for idx, token in enumerate(Vd):\n",
    "    hindi_vocab[token] = idx + 3\n",
    "\n",
    "hindi_vocab[\"<PAD>\"] = 0\n",
    "hindi_vocab[\"<SOS>\"] = 1\n",
    "hindi_vocab[\"<EOS>\"] = 2\n",
    "\n",
    "Vd = hindi_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[म्यूरियल, अब, बीस, साल, की, है, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[वैसा, नहीं, होगा, ।]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[मुझें, तुम्हारी, याद, आ, रही, है, ।]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0        [म्यूरियल, अब, बीस, साल, की, हो, गई, है, ।]  \n",
       "1                [म्यूरियल, अब, बीस, साल, की, है, ।]  \n",
       "2  [मैं, इस, दुनिया, में, शिक्षा, पर, बहुत, निराश...  \n",
       "3                              [वैसा, नहीं, होगा, ।]  \n",
       "4              [मुझें, तुम्हारी, याद, आ, रही, है, ।]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hindi_tokens_to_ids(tokenized_hindi_sentence):\n",
    "    return [Vd[token] for token in tokenized_hindi_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentence\"] = data[\"DstSentence\"].apply(convert_hindi_tokens_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 3313, 6899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[7044, 3685, 2962, 6899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[2688, 5411, 3867, 4586, 2142, 3313, 6899]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \n",
       "0  [2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...  \n",
       "1          [2408, 255, 3275, 6162, 6057, 3313, 6899]  \n",
       "2  [1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...  \n",
       "3                           [7044, 3685, 2962, 6899]  \n",
       "4         [2688, 5411, 3867, 4586, 2142, 3313, 6899]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sos_token_id(hindi_sentence_token_ids_list):\n",
    "    return [1] + hindi_sentence_token_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_eos_token_id(hindi_sentence_token_ids_list):\n",
    "    return hindi_sentence_token_ids_list + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"DstSentenceInput\"] = data[\"DstSentence\"].apply(insert_sos_token_id)\n",
    "data[\"DstSentenceLabel\"] = data[\"DstSentence\"].apply(insert_eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentenceID</th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceID</th>\n",
       "      <th>DstSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>485968</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...</td>\n",
       "      <td>[1, 2408, 255, 3275, 6162, 6057, 162, 2378, 33...</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282</td>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>2060319</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 3313, 6899]</td>\n",
       "      <td>[1, 2408, 255, 3275, 6162, 6057, 3313, 6899]</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 3313, 6899, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294</td>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>485564</td>\n",
       "      <td>[1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...</td>\n",
       "      <td>[1, 1836, 5469, 2644, 2041, 2310, 6559, 1134, ...</td>\n",
       "      <td>[1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>2060320</td>\n",
       "      <td>[7044, 3685, 2962, 6899]</td>\n",
       "      <td>[1, 7044, 3685, 2962, 6899]</td>\n",
       "      <td>[7044, 3685, 2962, 6899, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1308</td>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>2060321</td>\n",
       "      <td>[2688, 5411, 3867, 4586, 2142, 3313, 6899]</td>\n",
       "      <td>[1, 2688, 5411, 3867, 4586, 2142, 3313, 6899]</td>\n",
       "      <td>[2688, 5411, 3867, 4586, 2142, 3313, 6899, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SrcSentenceID                            SrcSentence  DstSentenceID  \\\n",
       "0           1282     [4159, 23, 14018, 19, 460, 230, 5]         485968   \n",
       "1           1282     [4159, 23, 14018, 19, 460, 230, 5]        2060319   \n",
       "2           1294  [2855, 16, 48, 296, 26963, 7, 140, 5]         485564   \n",
       "3           1302            [466, 751, 31, 17, 1837, 5]        2060320   \n",
       "4           1308                      [27, 3041, 25, 5]        2060321   \n",
       "\n",
       "                                         DstSentence  \\\n",
       "0  [2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...   \n",
       "1          [2408, 255, 3275, 6162, 6057, 3313, 6899]   \n",
       "2  [1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...   \n",
       "3                           [7044, 3685, 2962, 6899]   \n",
       "4         [2688, 5411, 3867, 4586, 2142, 3313, 6899]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 2408, 255, 3275, 6162, 6057, 162, 2378, 33...   \n",
       "1       [1, 2408, 255, 3275, 6162, 6057, 3313, 6899]   \n",
       "2  [1, 1836, 5469, 2644, 2041, 2310, 6559, 1134, ...   \n",
       "3                        [1, 7044, 3685, 2962, 6899]   \n",
       "4      [1, 2688, 5411, 3867, 4586, 2142, 3313, 6899]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...  \n",
       "1       [2408, 255, 3275, 6162, 6057, 3313, 6899, 2]  \n",
       "2  [1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...  \n",
       "3                        [7044, 3685, 2962, 6899, 2]  \n",
       "4      [2688, 5411, 3867, 4586, 2142, 3313, 6899, 2]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=[\"SrcSentenceID\",\"DstSentenceID\",\"DstSentence\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SrcSentence</th>\n",
       "      <th>DstSentenceInput</th>\n",
       "      <th>DstSentenceLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 2408, 255, 3275, 6162, 6057, 162, 2378, 33...</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n",
       "      <td>[1, 2408, 255, 3275, 6162, 6057, 3313, 6899]</td>\n",
       "      <td>[2408, 255, 3275, 6162, 6057, 3313, 6899, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n",
       "      <td>[1, 1836, 5469, 2644, 2041, 2310, 6559, 1134, ...</td>\n",
       "      <td>[1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[466, 751, 31, 17, 1837, 5]</td>\n",
       "      <td>[1, 7044, 3685, 2962, 6899]</td>\n",
       "      <td>[7044, 3685, 2962, 6899, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27, 3041, 25, 5]</td>\n",
       "      <td>[1, 2688, 5411, 3867, 4586, 2142, 3313, 6899]</td>\n",
       "      <td>[2688, 5411, 3867, 4586, 2142, 3313, 6899, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SrcSentence  \\\n",
       "0     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "1     [4159, 23, 14018, 19, 460, 230, 5]   \n",
       "2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n",
       "3            [466, 751, 31, 17, 1837, 5]   \n",
       "4                      [27, 3041, 25, 5]   \n",
       "\n",
       "                                    DstSentenceInput  \\\n",
       "0  [1, 2408, 255, 3275, 6162, 6057, 162, 2378, 33...   \n",
       "1       [1, 2408, 255, 3275, 6162, 6057, 3313, 6899]   \n",
       "2  [1, 1836, 5469, 2644, 2041, 2310, 6559, 1134, ...   \n",
       "3                        [1, 7044, 3685, 2962, 6899]   \n",
       "4      [1, 2688, 5411, 3867, 4586, 2142, 3313, 6899]   \n",
       "\n",
       "                                    DstSentenceLabel  \n",
       "0  [2408, 255, 3275, 6162, 6057, 162, 2378, 3313,...  \n",
       "1       [2408, 255, 3275, 6162, 6057, 3313, 6899, 2]  \n",
       "2  [1836, 5469, 2644, 2041, 2310, 6559, 1134, 626...  \n",
       "3                        [7044, 3685, 2962, 6899, 2]  \n",
       "4      [2688, 5411, 3867, 4586, 2142, 3313, 6899, 2]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data[\"SrcSentence\"])\n",
    "Y_input = list(data[\"DstSentenceInput\"])\n",
    "Y_label = list(data[\"DstSentenceLabel\"])\n",
    "\n",
    "X_tensor = [torch.tensor(eng_tokenized_ids) for eng_tokenized_ids in X]\n",
    "Y_input_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_input]\n",
    "Y_label_tensor = [torch.tensor(hin_tokenized_ids) for hin_tokenized_ids in Y_label]\n",
    "\n",
    "X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\n",
    "Y_input_padded = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\n",
    "Y_label_padded = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = X_padded.shape[1]\n",
    "Nd = Y_label_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.attention_probabilities = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self,encoder_outputs,decoder_lstm_layer_outputs):\n",
    "        \n",
    "        decoder_lstm_layer_outputs = torch.transpose(decoder_lstm_layer_outputs,dim0=1,dim1=2)\n",
    "        alignment_scores = torch.bmm(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        attention_weights = self.attention_probabilities(alignment_scores)\n",
    "        attention_weights = torch.transpose(attention_weights,dim0=1,dim1=2)\n",
    "        context_vectors = torch.bmm(attention_weights,encoder_outputs)\n",
    "\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,topic_vector_dim):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.first_emebdding_layer = torch.nn.Embedding(num_embeddings=src_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        \n",
    "    def forward(self,X_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_emebdding_layer(X_padded_mini_batch)\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.second_lstm_layer(first_embedding_layer_out)\n",
    "\n",
    "        return encoder_outputs,(final_encoder_output,final_candidate_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.first_embedding_layer = torch.nn.Embedding(num_embeddings=dst_lang_vocab_size,\n",
    "                                                        embedding_dim=topic_vector_dim)\n",
    "        self.second_lstm_layer = torch.nn.LSTM(input_size=topic_vector_dim,hidden_size=topic_vector_dim,\n",
    "                                               batch_first=True)\n",
    "        self.attention_layer = Attention()\n",
    "        self.output_layer = torch.nn.Linear(in_features=topic_vector_dim*2,out_features=dst_lang_vocab_size)\n",
    "        self.output_layer_activation = torch.nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self,encoder_outputs,initial_hidden_state,initial_candidate_cell_state,\n",
    "                Y_padded_mini_batch):\n",
    "\n",
    "        first_embedding_layer_out = self.first_embedding_layer(Y_padded_mini_batch)\n",
    "        decoder_lstm_layer_outputs,final_cell_hidden_states = self.second_lstm_layer(first_embedding_layer_out,\n",
    "                                                                                    (initial_hidden_state,\n",
    "                                                                                    initial_candidate_cell_state))\n",
    "        context_vectors = self.attention_layer(encoder_outputs,decoder_lstm_layer_outputs)\n",
    "        concatenated_lstm_layer_output = torch.concatenate(tensors=(decoder_lstm_layer_outputs,context_vectors),dim=2)\n",
    "        affine_transformed_output = self.output_layer(concatenated_lstm_layer_output)\n",
    "        decoder_outputs = self.output_layer_activation(affine_transformed_output)\n",
    "\n",
    "        return decoder_outputs, final_cell_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncDecWithAttn(torch.nn.Module):\n",
    "    def __init__(self,src_lang_vocab_size,dst_lang_vocab_size,topic_vector_dim):\n",
    "        super(Seq2SeqEncDecWithAttn,self).__init__()\n",
    "        self.encoder = Encoder(src_lang_vocab_size,topic_vector_dim)\n",
    "        self.decoder = Decoder(dst_lang_vocab_size,topic_vector_dim)\n",
    "\n",
    "    def forward(self,X_padded_mini_batch,Y_padded_mini_batch_input):\n",
    "\n",
    "        encoder_outputs,(final_encoder_output,final_candidate_cell_state) = self.encoder(X_padded_mini_batch)\n",
    "        Y_hat_mini_batch, final_cell_hidden_states = self.decoder(encoder_outputs,final_encoder_output,\n",
    "                                                                  final_candidate_cell_state,Y_padded_mini_batch_input)\n",
    "        \n",
    "        return Y_hat_mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded_train = X_padded[0:13000]\n",
    "Y_input_padded_train = Y_input_padded[0:13000]\n",
    "Y_label_padded_train = Y_label_padded[0:13000]\n",
    "\n",
    "X_padded_test = X_padded[13000:]\n",
    "Y_input_padded_test = Y_input_padded[13000:]\n",
    "Y_label_padded_test = Y_label_padded[13000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Mini Batch #0, CCE Loss = 8.863903999328613\n",
      "Epoch #0, Mini Batch #25, CCE Loss = 7.980758190155029\n",
      "Epoch #0, Mini Batch #50, CCE Loss = 7.991759300231934\n",
      "Epoch #0, Mini Batch #75, CCE Loss = 7.990304470062256\n",
      "Epoch #0, Mini Batch #100, CCE Loss = 7.992072105407715\n",
      "Epoch #0, Mini Batch #125, CCE Loss = 7.977436542510986\n",
      "Epoch #0, Mini Batch #150, CCE Loss = 7.957982540130615\n",
      "Epoch #0, Mini Batch #175, CCE Loss = 7.971670627593994\n",
      "Epoch #0, Mini Batch #200, CCE Loss = 7.947995662689209\n",
      "Epoch #0, Mini Batch #225, CCE Loss = 7.947859287261963\n",
      "Epoch #0, Mini Batch #250, CCE Loss = 7.953736305236816\n",
      "Epoch #0, Mini Batch #275, CCE Loss = 7.9552321434021\n",
      "Epoch #0, Mini Batch #300, CCE Loss = 7.935338497161865\n",
      "Epoch #0, Mini Batch #325, CCE Loss = 7.9902825355529785\n",
      "Epoch #0, Mini Batch #350, CCE Loss = 7.956906795501709\n",
      "Epoch #0, Mini Batch #375, CCE Loss = 7.943914413452148\n",
      "Epoch #0, Mini Batch #400, CCE Loss = 7.958964824676514\n",
      "Epoch #0, Mini Batch #425, CCE Loss = 7.958526134490967\n",
      "Epoch #0, Mini Batch #450, CCE Loss = 7.954505920410156\n",
      "Epoch #0, Mini Batch #475, CCE Loss = 7.939459800720215\n",
      "Epoch #1, Mini Batch #0, CCE Loss = 7.939206123352051\n",
      "Epoch #1, Mini Batch #25, CCE Loss = 7.965305328369141\n",
      "Epoch #1, Mini Batch #50, CCE Loss = 7.974511623382568\n",
      "Epoch #1, Mini Batch #75, CCE Loss = 7.965920448303223\n",
      "Epoch #1, Mini Batch #100, CCE Loss = 7.986902236938477\n",
      "Epoch #1, Mini Batch #125, CCE Loss = 7.9713969230651855\n",
      "Epoch #1, Mini Batch #150, CCE Loss = 7.954072952270508\n",
      "Epoch #1, Mini Batch #175, CCE Loss = 7.966921806335449\n",
      "Epoch #1, Mini Batch #200, CCE Loss = 7.945818901062012\n",
      "Epoch #1, Mini Batch #225, CCE Loss = 7.945591449737549\n",
      "Epoch #1, Mini Batch #250, CCE Loss = 7.953026294708252\n",
      "Epoch #1, Mini Batch #275, CCE Loss = 7.950564384460449\n",
      "Epoch #1, Mini Batch #300, CCE Loss = 7.932186126708984\n",
      "Epoch #1, Mini Batch #325, CCE Loss = 7.98324728012085\n",
      "Epoch #1, Mini Batch #350, CCE Loss = 7.951592922210693\n",
      "Epoch #1, Mini Batch #375, CCE Loss = 7.943900108337402\n",
      "Epoch #1, Mini Batch #400, CCE Loss = 7.9507060050964355\n",
      "Epoch #1, Mini Batch #425, CCE Loss = 7.954678058624268\n",
      "Epoch #1, Mini Batch #450, CCE Loss = 7.952383041381836\n",
      "Epoch #1, Mini Batch #475, CCE Loss = 7.937960147857666\n",
      "Epoch #2, Mini Batch #0, CCE Loss = 7.9330220222473145\n",
      "Epoch #2, Mini Batch #25, CCE Loss = 7.961984634399414\n",
      "Epoch #2, Mini Batch #50, CCE Loss = 7.974266529083252\n",
      "Epoch #2, Mini Batch #75, CCE Loss = 7.963146209716797\n",
      "Epoch #2, Mini Batch #100, CCE Loss = 7.9840240478515625\n",
      "Epoch #2, Mini Batch #125, CCE Loss = 7.970061302185059\n",
      "Epoch #2, Mini Batch #150, CCE Loss = 7.951733589172363\n",
      "Epoch #2, Mini Batch #175, CCE Loss = 7.96449089050293\n",
      "Epoch #2, Mini Batch #200, CCE Loss = 7.9416184425354\n",
      "Epoch #2, Mini Batch #225, CCE Loss = 7.942533493041992\n",
      "Epoch #2, Mini Batch #250, CCE Loss = 7.952088356018066\n",
      "Epoch #2, Mini Batch #275, CCE Loss = 7.946847915649414\n",
      "Epoch #2, Mini Batch #300, CCE Loss = 7.930840492248535\n",
      "Epoch #2, Mini Batch #325, CCE Loss = 7.980528831481934\n",
      "Epoch #2, Mini Batch #350, CCE Loss = 7.952911853790283\n",
      "Epoch #2, Mini Batch #375, CCE Loss = 7.9371867179870605\n",
      "Epoch #2, Mini Batch #400, CCE Loss = 7.9436492919921875\n",
      "Epoch #2, Mini Batch #425, CCE Loss = 7.9512529373168945\n",
      "Epoch #2, Mini Batch #450, CCE Loss = 7.949890613555908\n",
      "Epoch #2, Mini Batch #475, CCE Loss = 7.93617582321167\n",
      "Epoch #3, Mini Batch #0, CCE Loss = 7.930116653442383\n",
      "Epoch #3, Mini Batch #25, CCE Loss = 7.9560418128967285\n",
      "Epoch #3, Mini Batch #50, CCE Loss = 7.969242095947266\n",
      "Epoch #3, Mini Batch #75, CCE Loss = 7.963382720947266\n",
      "Epoch #3, Mini Batch #100, CCE Loss = 7.9835309982299805\n",
      "Epoch #3, Mini Batch #125, CCE Loss = 7.968775749206543\n",
      "Epoch #3, Mini Batch #150, CCE Loss = 7.949612617492676\n",
      "Epoch #3, Mini Batch #175, CCE Loss = 7.960759162902832\n",
      "Epoch #3, Mini Batch #200, CCE Loss = 7.94208288192749\n",
      "Epoch #3, Mini Batch #225, CCE Loss = 7.940500736236572\n",
      "Epoch #3, Mini Batch #250, CCE Loss = 7.951159954071045\n",
      "Epoch #3, Mini Batch #275, CCE Loss = 7.941701412200928\n",
      "Epoch #3, Mini Batch #300, CCE Loss = 7.929069995880127\n",
      "Epoch #3, Mini Batch #325, CCE Loss = 7.976738929748535\n",
      "Epoch #3, Mini Batch #350, CCE Loss = 7.947051525115967\n",
      "Epoch #3, Mini Batch #375, CCE Loss = 7.935999393463135\n",
      "Epoch #3, Mini Batch #400, CCE Loss = 7.9427809715271\n",
      "Epoch #3, Mini Batch #425, CCE Loss = 7.950991153717041\n",
      "Epoch #3, Mini Batch #450, CCE Loss = 7.947987079620361\n",
      "Epoch #3, Mini Batch #475, CCE Loss = 7.934906482696533\n",
      "Epoch #4, Mini Batch #0, CCE Loss = 7.92936897277832\n",
      "Epoch #4, Mini Batch #25, CCE Loss = 7.955994606018066\n",
      "Epoch #4, Mini Batch #50, CCE Loss = 7.968308448791504\n",
      "Epoch #4, Mini Batch #75, CCE Loss = 7.962378025054932\n",
      "Epoch #4, Mini Batch #100, CCE Loss = 7.9827880859375\n",
      "Epoch #4, Mini Batch #125, CCE Loss = 7.968310356140137\n",
      "Epoch #4, Mini Batch #150, CCE Loss = 7.949288845062256\n",
      "Epoch #4, Mini Batch #175, CCE Loss = 7.960363388061523\n",
      "Epoch #4, Mini Batch #200, CCE Loss = 7.939913749694824\n",
      "Epoch #4, Mini Batch #225, CCE Loss = 7.939731121063232\n",
      "Epoch #4, Mini Batch #250, CCE Loss = 7.950077533721924\n",
      "Epoch #4, Mini Batch #275, CCE Loss = 7.941561698913574\n",
      "Epoch #4, Mini Batch #300, CCE Loss = 7.928054332733154\n",
      "Epoch #4, Mini Batch #325, CCE Loss = 7.976143836975098\n",
      "Epoch #4, Mini Batch #350, CCE Loss = 7.94627571105957\n",
      "Epoch #4, Mini Batch #375, CCE Loss = 7.9365386962890625\n",
      "Epoch #4, Mini Batch #400, CCE Loss = 7.941894054412842\n",
      "Epoch #4, Mini Batch #425, CCE Loss = 7.9506940841674805\n",
      "Epoch #4, Mini Batch #450, CCE Loss = 7.947315692901611\n",
      "Epoch #4, Mini Batch #475, CCE Loss = 7.933836936950684\n"
     ]
    }
   ],
   "source": [
    "nw = Seq2SeqEncDecWithAttn(src_lang_vocab_size=len(Vs),dst_lang_vocab_size=len(Vd),topic_vector_dim=32)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(params=nw.parameters())\n",
    "epochs = 5\n",
    "mb_size = 26\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(X_padded_train.shape[0]//mb_size):\n",
    "\n",
    "        X_train_mb = X_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_input_train_mb = Y_input_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "        Y_label_train_mb = Y_label_padded_train[i*mb_size:(i+1)*mb_size]\n",
    "\n",
    "        Y_label_train_mb = Y_label_train_mb.reshape(Y_label_train_mb.shape[0]*Y_label_train_mb.shape[1],)\n",
    "\n",
    "        Y_pred_train_mb = nw(X_train_mb,Y_input_train_mb)\n",
    "        Y_pred_train_mb = Y_pred_train_mb.reshape(Y_pred_train_mb.shape[0]*Y_pred_train_mb.shape[1],\n",
    "                                                  Y_pred_train_mb.shape[2])\n",
    "        \n",
    "\n",
    "        loss_fn_value = loss_fn(Y_pred_train_mb,Y_label_train_mb)\n",
    "\n",
    "        loss_fn_value.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 25 == 0:\n",
    "            print(\"Epoch #{}, Mini Batch #{}, CCE Loss = {}\".format(epoch,i,loss_fn_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vd_idx2vocab = dict(zip(Vd.values(),Vd.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_translation(eng_sentence):\n",
    "\n",
    "    tokenized_eng_sentence = tokenizer.tokenize(eng_sentence)\n",
    "    print(tokenized_eng_sentence)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokenized_eng_sentence)\n",
    "    token_ids_tensor = torch.tensor(token_ids)\n",
    "    token_ids_tensor = torch.unsqueeze(token_ids_tensor,0)\n",
    "    padded_token_ids = torch.nn.utils.rnn.pad_sequence(token_ids_tensor)\n",
    "\n",
    "    encoder_outputs,(final_encoder_output,final_candidate_cell_state) = nw.encoder(padded_token_ids)\n",
    "    decoder_first_time_step_input = torch.tensor([hindi_vocab[\"<SOS>\"]]*mb_size)\n",
    "    #decoder_first_time_step_input = torch.unsqueeze(decoder_first_time_step_input,1)\n",
    "    final_encoder_output = torch.squeeze(final_encoder_output,0)\n",
    "    final_candidate_cell_state = torch.squeeze(final_candidate_cell_state,0)\n",
    "    decoder_first_time_step_output, hidden_cell_states = nw.decoder(encoder_outputs,\n",
    "                                                                          final_encoder_output,\n",
    "                                                                          final_candidate_cell_state,\n",
    "                                                                          decoder_first_time_step_input)\n",
    "    \n",
    "    generated_token_id = torch.argmax(decoder_first_time_step_output,1)\n",
    "    generated_token_id = torch.unsqueeze(generated_token_id,1)\n",
    "\n",
    "    print(Vd_idx2vocab[generated_token_id])\n",
    "\n",
    "    for i in range(Nd-1):\n",
    "\n",
    "        generated_softmax_probabilities,hidden_cell_states = nw.decoder(encoder_outputs,\n",
    "                                                                        hidden_cell_states[0],hidden_cell_states[1],\n",
    "                                                                        generated_token_id)\n",
    "        generated_token_id = torch.argmax(generated_softmax_probabilities,1)\n",
    "\n",
    "        if generated_token_id == Vd[\"<EOS\"]:\n",
    "            break\n",
    "\n",
    "        print(Vd_idx2vocab[generated_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁The', '▁semester', '▁is', '▁going', '▁to', '▁end']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 1, 32), got [6, 1, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe semester is going to end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 15\u001b[0m, in \u001b[0;36mgenerate_translation\u001b[0;34m(eng_sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m final_encoder_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(final_encoder_output,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m final_candidate_cell_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(final_candidate_cell_state,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m decoder_first_time_step_output, hidden_cell_states \u001b[38;5;241m=\u001b[39m \u001b[43mnw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mfinal_encoder_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mfinal_candidate_cell_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mdecoder_first_time_step_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m generated_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(decoder_first_time_step_output,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m generated_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(generated_token_id,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, encoder_outputs, initial_hidden_state, initial_candidate_cell_state, Y_padded_mini_batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,encoder_outputs,initial_hidden_state,initial_candidate_cell_state,\n\u001b[1;32m     13\u001b[0m             Y_padded_mini_batch):\n\u001b[1;32m     15\u001b[0m     first_embedding_layer_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_embedding_layer(Y_padded_mini_batch)\n\u001b[0;32m---> 16\u001b[0m     decoder_lstm_layer_outputs,final_cell_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond_lstm_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_embedding_layer_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_hidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                                                \u001b[49m\u001b[43minitial_candidate_cell_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     context_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_layer(encoder_outputs,decoder_lstm_layer_outputs)\n\u001b[1;32m     20\u001b[0m     concatenated_lstm_layer_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate(tensors\u001b[38;5;241m=\u001b[39m(decoder_lstm_layer_outputs,context_vectors),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1120\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1003\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[1;32m    999\u001b[0m     hidden: Tuple[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[1;32m   1002\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[0;32m-> 1003\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[1;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1012\u001b[0m     )\n",
      "File \u001b[0;32m~/AiML-projects/language-translation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:347\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_hidden_size\u001b[39m(\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    342\u001b[0m     hx: Tensor,\n\u001b[1;32m    343\u001b[0m     expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    344\u001b[0m     msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[0;32m--> 347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 1, 32), got [6, 1, 32]"
     ]
    }
   ],
   "source": [
    "generate_translation(\"The semester is going to end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
